# -*- coding: utf-8 -*-
"""
Created on Wed Apr 11 08:23:34 2018

@author: twang


"""
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
#from __future__ import unicode_literals


from collections import defaultdict
import cv2  # NOQA (Must import before importing caffe2 due to bug in cv2)
import time
import numpy as np
#import argparse

from caffe2.python import workspace
from core.config import assert_and_infer_cfg
from core.config import cfg
from core.config import merge_cfg_from_file
from utils.io import cache_url
from utils.timer import Timer
import core.test_engine as infer_engine
import datasets.dummy_datasets as dummy_datasets
import utils.c2 as c2_utils

import pycocotools.mask as mask_util
from utils.colormap import colormap

#import utils.vis as vis_utils

c2_utils.import_detectron_ops()
# OpenCL may be enabled by default in OpenCV3; disable it because it's not
# thread safe and causes unwanted GPU memory allocations.
cv2.ocl.setUseOpenCL(False)


_GRAY = (218, 227, 218)
_GREEN = (18, 127, 15)
_WHITE = (255, 255, 255)
        


def convert_from_cls_format(cls_boxes, cls_segms, cls_keyps):
    """Convert from the class boxes/segms/keyps format generated by the testing
    code.
    """
    box_list = [b for b in cls_boxes if len(b) > 0]
    if len(box_list) > 0:
        boxes = np.concatenate(box_list)
    else:
        boxes = None
    if cls_segms is not None:
        segms = [s for slist in cls_segms for s in slist]
    else:
        segms = None
    if cls_keyps is not None:
        keyps = [k for klist in cls_keyps for k in klist]
    else:
        keyps = None
    classes = []
    for j in range(len(cls_boxes)):
        classes += [j] * len(cls_boxes[j])
    return boxes, segms, keyps, classes
    
def vis_mask(img, mask, col, alpha=0.4, show_border=True, border_thick=1):
    """Visualizes a single binary mask."""

    img = img.astype(np.float32)
    idx = np.nonzero(mask)

    img[idx[0], idx[1], :] *= 1.0 - alpha
    img[idx[0], idx[1], :] += alpha * col

    if show_border:
        _, contours, _ = cv2.findContours(
            mask.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)
        cv2.drawContours(img, contours, -1, _WHITE, border_thick, cv2.LINE_AA)

    return img.astype(np.uint8)


def vis_class(img, pos, class_str, font_scale=0.35):
    """Visualizes the class."""
    x0, y0 = int(pos[0]), int(pos[1])
    # Compute text size.
    txt = class_str
    font = cv2.FONT_HERSHEY_SIMPLEX
    ((txt_w, txt_h), _) = cv2.getTextSize(txt, font, font_scale, 1)
    # Place text background.
    back_tl = x0, y0 - int(1.3 * txt_h)
    back_br = x0 + txt_w, y0
    cv2.rectangle(img, back_tl, back_br, _GREEN, -1)
    # Show text.
    txt_tl = x0, y0 - int(0.3 * txt_h)
    cv2.putText(img, txt, txt_tl, font, font_scale, _GRAY, lineType=cv2.LINE_AA)
    return img


def vis_bbox(img, bbox, thick=1):
    """Visualizes a bounding box."""
    (x0, y0, w, h) = bbox
    x1, y1 = int(x0 + w), int(y0 + h)
    x0, y0 = int(x0), int(y0)
    cv2.rectangle(img, (x0, y0), (x1, y1), _GREEN, thickness=thick)
    return img
    
def get_class_string(class_index, score, dataset):
    class_text = dataset.classes[class_index] if dataset is not None else \
        'id{:d}'.format(class_index)
    return class_text + ' {:0.2f}'.format(score).lstrip('0'), class_text
       
        
def main():
    
    cfg_file = r'/home/twang/Documents/detectron/configs/12_2017_baselines/e2e_mask_rcnn_R-101-FPN_2x.yaml'
    weights_file = r'/home/twang/Documents/detectron/model-weights/mask_rcnn_R-101-FPN_2x_model_final.pkl'
    
    merge_cfg_from_file(cfg_file)
    cfg.NUM_GPUS = 1
    weights = cache_url(weights_file, cfg.DOWNLOAD_CACHE)
    
    assert_and_infer_cfg()
    
    model = infer_engine.initialize_model_from_cfg(weights)
    
    dummy_coco_dataset = dummy_datasets.get_coco_dataset()

    
    video_dir = '/media/network_shared_disk/WangTao/test_video/KLA_airport/Entrance_Peak_Hour.avi'
    
    cap = cv2.VideoCapture(video_dir)
    
    print(*'MJPG')
    
    fourcc = cv2.VideoWriter_fourcc(*'MJPG')
    
    video_output = cv2.VideoWriter("out.mp4",fourcc,5,(1280,720))
    
    
    while cap.isOpened():
        
        t1 = time.time()
        
        ret, frame = cap.read()

        if not ret:
            break
        
        frame = cv2.resize(frame,dsize=(1280,720))   
        
        timers = defaultdict(Timer)

        with c2_utils.NamedCudaScope(0):
            cls_boxes, cls_segms, cls_keyps = infer_engine.im_detect_all(model, frame, None, timers=timers) 
        
        thresh=0.7
        
        show_box = True
        
        show_box = True
        show_class = True
        crop_person = True
        
        dataset=dummy_coco_dataset
        
        frame_for_person_crop = frame.copy()
        frame_for_mask = frame.copy()
        
        """Constructs a numpy array with the detections visualized."""
        if isinstance(cls_boxes, list):
            boxes, segms, keypoints, classes = convert_from_cls_format(cls_boxes, cls_segms, cls_keyps)

        if boxes is None or boxes.shape[0] == 0 or max(boxes[:, 4]) < thresh:
            return frame

        if segms is not None and len(segms) > 0:
            masks = mask_util.decode(segms)
            color_list = colormap()
            mask_color_id = 0
            

        
        # Display in largest to smallest order to reduce occlusion
        areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
        sorted_inds = np.argsort(-areas)
        
        for i in sorted_inds:
            bbox = boxes[i, :4]
            score = boxes[i, -1]
            if score < thresh:
                continue   
                
            # show class (person, backpack, handbag, suitcase)
            class_default = ['person','backpack','handbag','suitcase']
            if show_class:
                class_str, class_text = get_class_string(classes[i], score, dataset)
                
                if class_text in class_default:
                    
                    frame = vis_class(frame, (bbox[0], bbox[1] - 2), class_str)
                    
                    #show bounding box
                    if show_box:
                        frame = vis_bbox(frame, (bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1]))
                        
                    # show mask
                    if segms is not None and len(segms) > i:
                        color_mask = color_list[mask_color_id % len(color_list), 0:3]
                        mask_color_id += 1
                        frame_for_mask = vis_mask(frame_for_mask, masks[..., i], color_mask)

        t2 = time.time()
        durr = float(t2-t1)
        fps = 1.0 / durr
        #cv2.putText(frame,"fps:%.3f"%fps,(20,20),4, 0.5, (0, 255, 0), 1, cv2.LINE_AA)
        cv2.imshow('Detection using box', frame)
        cv2.imshow('Detection using mask',frame_for_mask)
        
        video_output.write(frame)
        #video_mask.write(frame_for_mask)
        
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
                
    cap.release() 
    video_output.release()
    cv2.destroyAllWindows()            

if __name__ == '__main__':
    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])
    main()